---
category: literaturenote
tags: Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning
citekey: saakyan2025a
status: unread
dateread: "[saakyan2025.pdf](zotero://select/library/items/ZLT7UKGR)"
---


> [!Cite]
> Saakyan, William, Matthias Norden, Lola Eversmann, et al. â€œImproving Autism Detection with Multimodal Behavioral Analysis.â€ arXiv:2509.21352. Preprint, arXiv, September 19, 2025. [https://doi.org/10.48550/arXiv.2509.21352](https://doi.org/10.48550/arXiv.2509.21352).

>[!Synth]
>**Contribution**:: 
>
>**Related**:: 
>

>[!md]
> **FirstAuthor**:: Saakyan, William  
> **Author**:: Norden, Matthias  
> **Author**:: Eversmann, Lola  
> **Author**:: Kirsch, Simon  
> **Author**:: Lin, Muyu  
> **Author**:: Guendelman, Simon  
> **Author**:: Dziobek, Isabel  
> **Author**:: Drimalla, Hanna  
~    
> **Title**:: Improving Autism Detection with Multimodal Behavioral Analysis  
> **Year**:: 2025   
> **Citekey**:: saakyan2025a  
> **itemType**:: preprint  
> **DOI**:: 10.48550/arXiv.2509.21352    

> [!LINK] 
>
>  [saakyan2025.pdf](file://C:\Users\user\Nextcloud\Documents\Obsidian\ðŸŽ“%20PhD\ðŸ“‘%20Papers\PDF\saakyan2025.pdf).

> [!Abstract]
>
> Due to the complex and resource-intensive nature of diagnosing Autism Spectrum Condition (ASC), several computer-aided diagnostic support methods have been proposed to detect autism by analyzing behavioral cues in patient video data. While these models show promising results on some datasets, they struggle with poor gaze feature performance and lack of real-world generalizability. To tackle these challenges, we analyze a standardized video dataset comprising 168 participants with ASC (46% female) and 157 non-autistic participants (46% female), making it, to our knowledge, the largest and most balanced dataset available. We conduct a multimodal analysis of facial expressions, voice prosody, head motion, heart rate variability (HRV), and gaze behavior. To address the limitations of prior gaze models, we introduce novel statistical descriptors that quantify variability in eye gaze angles, improving gaze-based classification accuracy from 64% to 69% and aligning computational findings with clinical research on gaze aversion in ASC. Using late fusion, we achieve a classification accuracy of 74%, demonstrating the effectiveness of integrating behavioral markers across multiple modalities. Our findings highlight the potential for scalable, video-based screening tools to support autism assessment.
>.
> 
# Notes
>.


# Annotations%% begin annotations %%



### Imported: 2026-02-12 3:52 pm


<mark style="background-color: #ffd400">Quote</mark>
"To address the limitations of prior gaze models, we introduce novel statistical descriptors that quantify variability in eye gaze angles, improving gaze-based classification accuracy from 64% to 69% and aligning computational findings with clinical research on gaze aversion in ASC."

> Clinical Alignment


<mark style="background-color: #ffd400">Quote</mark>
"Our findings highlight the potential for scalable, video-based screening tools to support autism assessment."

> Scalability


<mark style="background-color: #ffd400">Quote</mark>
"This highlights the urgent need for objective, scalable, and accessible tools to support autism screening and behavioral assessment."

> Need for Objective Tools



%% end annotations %%


%% Import Date: 2026-02-12T15:53:14.551+01:00 %%
