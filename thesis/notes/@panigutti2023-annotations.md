---
category: literaturenote
tags: 
citekey: panigutti2023
status: unread
dateread: "[panigutti2023.pdf](zotero://select/library/items/35QC3D6L)"
---


> [!Cite]
> Panigutti, Cecilia, Andrea Beretta, Daniele Fadda, et al. â€œCo-Design of Human-Centered, Explainable AI for Clinical Decision Support.â€ _ACM Transactions on Interactive Intelligent Systems_ 13, no. 4 (2023): 1â€“35. [https://doi.org/10.1145/3587271](https://doi.org/10.1145/3587271).

>[!Synth]
>**Contribution**:: 
>
>**Related**:: 
>

>[!md]
> **FirstAuthor**:: Panigutti, Cecilia  
> **Author**:: Beretta, Andrea  
> **Author**:: Fadda, Daniele  
> **Author**:: Giannotti, Fosca  
> **Author**:: Pedreschi, Dino  
> **Author**:: Perotti, Alan  
> **Author**:: Rinzivillo, Salvatore  
~    
> **Title**:: Co-design of Human-centered, Explainable AI for Clinical Decision Support  
> **Year**:: 2023   
> **Citekey**:: panigutti2023  
> **itemType**:: journalArticle  
> **Journal**:: *ACM Transactions on Interactive Intelligent Systems*  
> **Volume**:: 13  
> **Issue**:: 4   
> **Pages**:: 1-35  
> **DOI**:: 10.1145/3587271    

> [!LINK] 
>
>  [panigutti2023.pdf](file://C:\Users\user\Nextcloud\Documents\Obsidian\ðŸŽ“%20PhD\ðŸ“‘%20Papers\PDF\panigutti2023.pdf).

> [!Abstract]
>
> eXplainable AI (XAI) involves two intertwined but separate challenges: the development of techniques to extract explanations from black-box AI models and the way such explanations are presented to users, i.e., the explanation user interface. Despite its importance, the second aspect has received limited attention so far in the literature. Effective AI explanation interfaces are fundamental for allowing human decision-makers to take advantage and oversee high-risk AI systems effectively. Following an iterative design approach, we present the first cycle of prototyping-testing-redesigning of an explainable AI technique and its explanation user interface for clinical Decision Support Systems (DSS). We first present an XAI technique that meets the technical requirements of the healthcare domain: sequential, ontology-linked patient data, and multi-label classification tasks. We demonstrate its applicability to explain a clinical DSS, and we design a first prototype of an explanation user interface. Next, we test such a prototype with healthcare providers and collect their feedback with a two-fold outcome: First, we obtain evidence that explanations increase usersâ€™ trust in the XAI system, and second, we obtain useful insights on the perceived deficiencies of their interaction with the system, so we can re-design a better, more human-centered explanation interface.
>.
> 
# Notes
>.


# Annotations%% begin annotations %%



### Imported: 2026-02-12 3:52 pm


<mark style="background-color: #ffd400">Quote</mark>
"Effective AI explanation interfaces are fundamental for allowing human decision-makers to take advantage and oversee high-risk AI systems effectively."

> <b>Enable Professional Oversight.</b> The interface must be designed to keep the clinician in control, ensuring they can oversee and verify the reasoning behind high-risk AI recommendations.


<mark style="background-color: #ffd400">Quote</mark>
"â€œWould like to see an explanation like, â€˜This patient is X% likely to undergo an acute MI within Y time. Suggest steps A, B, and C.â€™â€"

> <b>Provide Actionable Textual Explanations.</b> Clinicians prefer natural language explanations that offer specific risk percentages, clear timeframes, and concrete next steps.


<mark style="background-color: #ffd400">Quote</mark>
"Many also suggested simplifying the interface:"


<mark style="background-color: #ffd400">Quote</mark>
"Many also suggested simplifying the interface:  â€œList only those codes that are pertinent to a cardiovascular diagnosis.â€  â€œMake it simple.â€  â€œSimplify.â€  â€œ[I would like] a clearer and more precise explanation.â€"

> <b>Use a Layered View.</b> Avoid information overload by creating a "glanceable" primary dashboard for critical factors, with a secondary "deep dive" view for detailed analysis.



%% end annotations %%


%% Import Date: 2026-02-12T15:53:14.503+01:00 %%
